{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['temp'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\admin\\Masters-s-project\\masters_project\\machine_learning\\prediction.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=23'>24</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=24'>25</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mC:/Users/admin/Masters-s-project/masters_project/air_pollution_smog_1.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=25'>26</a>\u001b[0m     sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m;\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=30'>31</a>\u001b[0m     index_col\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=31'>32</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=33'>34</a>\u001b[0m \u001b[39m# scale the data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=34'>35</a>\u001b[0m target_scaler \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit(df[target])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=35'>36</a>\u001b[0m features_scaler \u001b[39m=\u001b[39m StandardScaler()\u001b[39m.\u001b[39mfit(df[features])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/admin/Masters-s-project/masters_project/machine_learning/prediction.ipynb#ch0000000?line=37'>38</a>\u001b[0m df[target] \u001b[39m=\u001b[39m target_scaler\u001b[39m.\u001b[39mtransform(df[target])\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['temp'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# source https://stackoverflow.com/questions/70361179/how-to-include-future-values-in-a-time-series-prediction-of-a-rnn-in-keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    LSTM,\n",
    "    TimeDistributed,\n",
    "    Concatenate,\n",
    "    Add,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# define the inputs\n",
    "target = [\"date,entry_id,PM1,PM2.5,PM10,temp,pressure,humidity\"]\n",
    "features = [\"date,entry_id,PM1,PM2.5,PM10,temp,pressure,humidity\"]\n",
    "sequence_length = 96\n",
    "\n",
    "# import the data\n",
    "df = pd.read_csv(\n",
    "    \"C:/Users/admin/Masters-s-project/masters_project/air_pollution_smog_1.csv\",\n",
    "    sep=\";\",\n",
    "    header=0,\n",
    "    low_memory=False,\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates={\"date\": [0]},\n",
    "    index_col=[\"date\"],\n",
    ")\n",
    "\n",
    "# scale the data\n",
    "target_scaler = StandardScaler().fit(df[target])\n",
    "features_scaler = StandardScaler().fit(df[features])\n",
    "\n",
    "df[target] = target_scaler.transform(df[target])\n",
    "df[features] = features_scaler.transform(df[features])\n",
    "\n",
    "# extract the input and output sequences\n",
    "X_encoder = []  # past features and target values\n",
    "X_decoder = []  # future features values\n",
    "y = []  # future target values\n",
    "\n",
    "for i in range(sequence_length, df.shape[0] - sequence_length):\n",
    "    X_encoder.append(df[features + target].iloc[i - sequence_length : i])\n",
    "    X_decoder.append(df[features].iloc[i : i + sequence_length])\n",
    "    y.append(df[target].iloc[i : i + sequence_length])\n",
    "\n",
    "X_encoder = np.array(X_encoder)\n",
    "X_decoder = np.array(X_decoder)\n",
    "y = np.array(y)\n",
    "\n",
    "# define the encoder and decoder\n",
    "def encoder(encoder_features):\n",
    "    y = LSTM(units=100, return_sequences=True)(encoder_features)\n",
    "    y = TimeDistributed(Dense(units=1))(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def decoder(decoder_features, encoder_outputs):\n",
    "    x = Concatenate(axis=-1)([decoder_features, encoder_outputs])\n",
    "    # x = Add()([decoder_features, encoder_outputs])\n",
    "    y = TimeDistributed(Dense(units=100, activation=\"relu\"))(x)\n",
    "    y = TimeDistributed(Dense(units=1))(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "# build the model\n",
    "encoder_features = Input(shape=X_encoder.shape[1:])\n",
    "decoder_features = Input(shape=X_decoder.shape[1:])\n",
    "encoder_outputs = encoder(encoder_features)\n",
    "decoder_outputs = decoder(decoder_features, encoder_outputs)\n",
    "model = Model([encoder_features, decoder_features], decoder_outputs)\n",
    "\n",
    "# train the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "model.fit([X_encoder, X_decoder], y, epochs=100, batch_size=128)\n",
    "\n",
    "\n",
    "# extract the last predicted sequence\n",
    "y_true = target_scaler.inverse_transform(y[-1, :])\n",
    "y_pred = target_scaler.inverse_transform(model.predict([X_encoder, X_decoder])[-1, :])\n",
    "\n",
    "# plot the last predicted sequence\n",
    "plt.plot(y_true.flatten(), label=\"actual\")\n",
    "plt.plot(y_pred.flatten(), label=\"predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "beedbe2faf2f7048d727558d0bc3221e7eba2a0b921cac4d4771b2feb8f74b30"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
